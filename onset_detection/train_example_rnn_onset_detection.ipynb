{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_ESP_RNN_For_GitHub_Refactored_OnsetBased_Detection_TRAIN_and_predicttest.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4UahyeVK_PC5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z63rW4fRchEM"
      },
      "source": [
        " script_info = \"\"\"\n",
        " This notebook was created based on https://github.com/slychief/ismir2018_tutorial/blob/master/Part_3b_RNN_Onset_Detection.ipynb;\n",
        " There is a huge part of this code that is exactly copied; we just adapted their model to our case.\n",
        " Also, this is an EXAMPLE notebook, so it gets easier to understand how the model\n",
        " was created, the only one change that I made from the original one, is that\n",
        " I put n_epochs = 10 instead of 100 (the original had 100 epochs) for making\n",
        " this easier to preprocess. When I do the eval results, I do it with the original\n",
        " model which will located in ./models folder of this repo. \n",
        " This is build on keras (tf as backend).\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcSsuwKecxKI",
        "outputId": "7beb0570-e96e-4b3e-d2de-e0792128a02e"
      },
      "source": [
        "!pip install madmom"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting madmom\n",
            "  Downloading madmom-0.16.1.tar.gz (20.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.4 in /usr/local/lib/python3.7/dist-packages (from madmom) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from madmom) (1.7.3)\n",
            "Requirement already satisfied: cython>=0.25 in /usr/local/lib/python3.7/dist-packages (from madmom) (0.29.32)\n",
            "Collecting mido>=1.2.8\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 3.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: madmom\n",
            "  Building wheel for madmom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for madmom: filename=madmom-0.16.1-cp37-cp37m-linux_x86_64.whl size=20939879 sha256=78ad550a4ffcf25dbea3a9d2c7cbf4ced84208261431209814bee6aab7661d6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/90/61/393ceef814b55b12d1b59b5ed3a2b2a3457a55d39b7363b975\n",
            "Successfully built madmom\n",
            "Installing collected packages: mido, madmom\n",
            "Successfully installed madmom-0.16.1 mido-1.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUQqBOKjcpl_"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import librosa\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import logging\n",
        "import warnings\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "# data processing / signal\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sympy import Interval\n",
        "import librosa\n",
        "import re\n",
        "# madmom\n",
        "import madmom\n",
        "from madmom.processors import ParallelProcessor, SequentialProcessor\n",
        "from madmom.audio.signal import SignalProcessor, FramedSignalProcessor\n",
        "from madmom.audio.stft import ShortTimeFourierTransformProcessor\n",
        "from madmom.audio.spectrogram import FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor, SpectrogramDifferenceProcessor\n",
        "# deeplearning\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, SimpleRNN, Bidirectional, Masking, LSTM, Dense\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# custom code"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JGOGS3Fcra_",
        "outputId": "c1a32a4b-7a50-4ea7-9290-bdf1b5f599c0"
      },
      "source": [
        "ROOT_DIR = \"/content/drive\"\n",
        "drive.mount(ROOT_DIR, force_remount=True)\n",
        "#Don't forget to type My Drive before the whole path\n",
        "MUSIC_DIR = os.path.join(ROOT_DIR,'My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/')\n",
        "AUDIO_DIR = ONSET_PATH = os.path.join(MUSIC_DIR,\"audio\",\"drum_only\")\n",
        "ANNOTATIONS_DIR = os.path.join(MUSIC_DIR,\"annotations\",\"class\",\"train\" )#/class/train\"\n",
        "example_suffix = \"for_github\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw1KZ4svc0f9"
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-gDTEgxc5j6",
        "outputId": "e4434968-d898-4c3e-db1d-5e66f0cdf605"
      },
      "source": [
        "FPS = 100\n",
        "os.listdir(ANNOTATIONS_DIR)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MusicDelta_Disco_class.txt',\n",
              " 'MusicDelta_Britpop_class.txt',\n",
              " 'MusicDelta_Rock_class.txt',\n",
              " 'MusicDelta_BebopJazz_class.txt',\n",
              " 'MusicDelta_Shadows_class.txt',\n",
              " 'MusicDelta_Reggae_class.txt',\n",
              " 'MusicDelta_CoolJazz_class.txt',\n",
              " 'MusicDelta_Rockabilly_class.txt',\n",
              " 'MusicDelta_FunkJazz_class.txt',\n",
              " 'MusicDelta_FusionJazz_class.txt',\n",
              " 'MusicDelta_80sRock_class.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# custom code, need to perform mount operation before importing it\n",
        "# you can find eval_utils script in the repo (./utils) ;\n",
        "#  cd where your downnloaded eval_utils script is\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/tesis_esp\"\n",
        "from eval_utils import search_correspondingpath_given_annotation, load_labels_just_onsets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KyQffiXsbBe",
        "outputId": "b2b52d70-83e0-411f-8fe7-c0569d6e48e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/tesis_esp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgBKt9STc7f0"
      },
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, path, files, annotation_files, audio_files):\n",
        "        self.path = path\n",
        "        self.files, self.annotation_files, self.audio_files = files, annotation_files, audio_files \n",
        "    def load_splits(self, path=None, fold_suffix='.fold'):\n",
        "        \"\"\"\n",
        "        We are NOT Using crossvalidation , so we weont use this function\n",
        "        \"\"\"\n",
        "        path = path if path is not None else self.path + '/splits'\n",
        "        self.split_files = madmom.utils.search_files(path, fold_suffix, recursion_depth=1)\n",
        "        # populate folds\n",
        "        self.folds = []\n",
        "        for i, split_file in enumerate(self.split_files):\n",
        "            fold_idx = []\n",
        "            with open(split_file) as f:\n",
        "                for file in f:\n",
        "                    file = file.strip()\n",
        "                    # get matching file idx\n",
        "                    try:\n",
        "                        idx = self.files.index(file)\n",
        "                        fold_idx.append(idx)\n",
        "                    except ValueError:\n",
        "                        warnings.warn('no matching audio/annotation files: %s' % file)\n",
        "                        continue\n",
        "            # set indices for fold\n",
        "            self.folds.append(np.array(fold_idx))\n",
        "            \n",
        "    def pre_process(self, pre_processor):\n",
        "        self.x = [pre_processor(file) for file in self.audio_files]\n",
        "        \n",
        "    def load_annoatations(self, widen=None):\n",
        "        \"Function for loading all annotations\"\n",
        "        self.annotations = [load_labels_just_onsets(file) for file in self.annotation_files]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfWIIg16O0CM",
        "outputId": "0a071fd7-1f1b-40e4-e090-a66d17610c7f"
      },
      "source": [
        "annotation_files_all = glob.glob(ANNOTATIONS_DIR+\"/*.txt\")\n",
        "audio_files_all = [\n",
        "              search_correspondingpath_given_annotation(annotation, ONSET_PATH)  \n",
        "              for annotation in annotation_files_all\n",
        "              ]\n",
        "# take base path with  suffix and then remove it\n",
        "files = [os.path.basename(file) for file in audio_files_all]\n",
        "files = [file.split(\".\")[0] for file in files]\n",
        "files\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MusicDelta_Disco_Drum',\n",
              " 'MusicDelta_Britpop_Drum',\n",
              " 'MusicDelta_Rock_Drum',\n",
              " 'MusicDelta_BebopJazz_Drum',\n",
              " 'MusicDelta_Shadows_Drum',\n",
              " 'MusicDelta_Reggae_Drum',\n",
              " 'MusicDelta_CoolJazz_Drum',\n",
              " 'MusicDelta_Rockabilly_Drum',\n",
              " 'MusicDelta_FunkJazz_Drum',\n",
              " 'MusicDelta_FusionJazz_Drum',\n",
              " 'MusicDelta_80sRock_Drum']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Load annotations into dataset obj"
      ],
      "metadata": {
        "id": "x8qQu03Josdm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58LLwebhdOLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb76eab0-ca3c-4cba-bed0-3dd72b96b5da"
      },
      "source": [
        "#  WARNING! file path MUST BE SORTED, when you pass the parameters\n",
        "onsets_db = Dataset(path = ONSET_PATH,\n",
        "                    files = files,\n",
        "                    annotation_files = annotation_files_all,\n",
        "                    audio_files= audio_files_all)\n",
        "onsets_db.load_annoatations()\n",
        "# first 5 onsets of the first file\n",
        "onsets_db.annotations[0][:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27, 0.273469, 0.41, 0.53, 0.68]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Preprocess the signal with 3 band filtered spectrogram differences:"
      ],
      "metadata": {
        "id": "_QReIa69oWvy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI8g9Uh-dYKR"
      },
      "source": [
        "# define pre-processor\n",
        "class OnsetPreProcessor(SequentialProcessor):\n",
        "  \"\"\"\n",
        "  Preprocessor of the raw signal: get the filtered spectroram differences with 3 band\n",
        "  \"\"\"\n",
        "  def __init__(self, frame_sizes=[1024, 2048, 4096], num_bands=[3, 6, 12]):\n",
        "      # resample to a fixed sample rate in order to get always the same number of filter bins\n",
        "      sig = SignalProcessor(num_channels=1, sample_rate=44100)\n",
        "      # process multi-resolution spec & diff in parallel\n",
        "      multi = ParallelProcessor([])\n",
        "      for frame_size, num_bands in zip(frame_sizes, num_bands):\n",
        "          # split audio signal in overlapping frames\n",
        "          frames = FramedSignalProcessor(frame_size=frame_size)\n",
        "          # compute STFT\n",
        "          stft = ShortTimeFourierTransformProcessor()\n",
        "          # filter the magnitudes\n",
        "          filt = FilteredSpectrogramProcessor(num_bands=num_bands)\n",
        "          # scale them logarithmically\n",
        "          spec = LogarithmicSpectrogramProcessor()\n",
        "          # stack positive differences\n",
        "          diff = SpectrogramDifferenceProcessor(positive_diffs=True, stack_diffs=np.hstack)\n",
        "          # process each frame size with spec and diff sequentially\n",
        "          multi.append(SequentialProcessor((frames, stft, filt, spec, diff)))\n",
        "      # instantiate a SequentialProcessor\n",
        "      super(OnsetPreProcessor, self).__init__((sig, multi, np.hstack))\n",
        "\n",
        "# create a callable pre-processor\n",
        "pp = OnsetPreProcessor()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop the transformed signals into a pkl"
      ],
      "metadata": {
        "id": "9oXBE_LEo1o_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eazCDlnpeh6f",
        "outputId": "171852b5-9982-4537-f6ee-ef963313223d"
      },
      "source": [
        "path_to_dump_preprocess = os.path.join(MUSIC_DIR,f\"onset_db_{example_suffix}.pkl\")\n",
        "if not os.path.exists(path_to_dump_preprocess):\n",
        "  onsets_db.pre_process(pp)\n",
        "  pickle.dump(onsets_db, open(path_to_dump_preprocess, 'wb'), protocol=2)\n",
        "  print(f\"Pickle dumped to: {path_to_dump_preprocess} \")\n",
        "else:\n",
        "  print(f\"Loading previously dumped pickle from: {path_to_dump_preprocess}\")\n",
        "  onsets_db = pickle.load(open(path_to_dump_preprocess,'rb'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading previously dumped pickle from: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/onset_db_for_github.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1DKRP8tvExA",
        "outputId": "0184cbbd-83bf-4493-becf-b00765e80a09"
      },
      "source": [
        "onsets_db.x[0].shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12478, 314)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW7jhHzmOSTq",
        "outputId": "b24c7541-fab9-420f-b36a-e08bf01d8a27"
      },
      "source": [
        "max2print = 5\n",
        "for idx in range(len(onsets_db.annotation_files)):\n",
        "  print(\"===================================\",idx,\"===================\")\n",
        "  print(\"Audiofile:\",onsets_db.audio_files[idx])\n",
        "  print(\"Annot:\",onsets_db.annotation_files[idx])\n",
        "  if idx>max2print:\n",
        "    break"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================== 0 ===================\n",
            "Audiofile: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/train/MusicDelta_Disco_Drum.wav\n",
            "Annot: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/annotations/class/train/MusicDelta_Disco_class.txt\n",
            "=================================== 1 ===================\n",
            "Audiofile: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/train/MusicDelta_Britpop_Drum.wav\n",
            "Annot: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/annotations/class/train/MusicDelta_Britpop_class.txt\n",
            "=================================== 2 ===================\n",
            "Audiofile: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/train/MusicDelta_Rock_Drum.wav\n",
            "Annot: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/annotations/class/train/MusicDelta_Rock_class.txt\n",
            "=================================== 3 ===================\n",
            "Audiofile: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/train/MusicDelta_BebopJazz_Drum.wav\n",
            "Annot: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/annotations/class/train/MusicDelta_BebopJazz_class.txt\n",
            "=================================== 4 ===================\n",
            "Audiofile: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/train/MusicDelta_Shadows_Drum.wav\n",
            "Annot: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/annotations/class/train/MusicDelta_Shadows_class.txt\n",
            "=================================== 5 ===================\n",
            "Audiofile: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/train/MusicDelta_Reggae_Drum.wav\n",
            "Annot: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/annotations/class/train/MusicDelta_Reggae_class.txt\n",
            "=================================== 6 ===================\n",
            "Audiofile: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/train/MusicDelta_CoolJazz_Drum.wav\n",
            "Annot: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/annotations/class/train/MusicDelta_CoolJazz_class.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIqby01BP3Xu"
      },
      "source": [
        "# So each audio file has a lot of onsets within, and this can be proving by looking at each file with its corresponding annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvklxaIyPIaf",
        "outputId": "3a67a1bb-e9c6-42e5-c0d1-2d3f3d28a6c4"
      },
      "source": [
        "onsets_db.x[1].shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3679, 314)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Preparing data for the rnn"
      ],
      "metadata": {
        "id": "mb5Jd_QWpDlE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8VGh5v5RVT4"
      },
      "source": [
        "class DataSequence(Sequence):\n",
        "    mask_value = -999  # only needed for batch sizes > 1\n",
        "    def __init__(self, x, y, batch_size=1, max_seq_length=None, fps=FPS):\n",
        "        self.x = x\n",
        "        # binarization\n",
        "        self.y = [madmom.utils.quantize_events(o, fps=fps, length=len(d))\n",
        "                  for o, d in zip(y, self.x)]\n",
        "        self.batch_size = batch_size\n",
        "        self.max_seq_length = max_seq_length\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "    def __getitem__(self, idx):\n",
        "        # determine which sequence(s) to use\n",
        "        x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        # pad them if needed\n",
        "        if self.batch_size > 1:\n",
        "            x = keras.preprocessing.sequence.pad_sequences(\n",
        "                x, maxlen=self.max_seq_length, dtype=np.float32, truncating='post', value=self.mask_value)\n",
        "            y = keras.preprocessing.sequence.pad_sequences(\n",
        "                y, maxlen=self.max_seq_length, dtype=np.int32, truncating='post', value=self.mask_value)\n",
        "        return np.array(x), np.array(y)[..., np.newaxis]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRpMIl4JR5FT"
      },
      "source": [
        "basedir  = os.path.join(MUSIC_DIR,f\"models_{example_suffix}\")\n",
        "if not os.path.exists(basedir ):\n",
        "  os.mkdir(basedir )\n",
        "  basedir  = os.path.join(basedir ,'onsets')\n",
        "  if not os.path.exists(basedir ):\n",
        "    os.mkdir(basedir)\n",
        "    print(\"MKDIR FINISHED:\",basedir )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fKkDt_3NSdjs",
        "outputId": "c82f9732-6aff-4ecb-9205-dc571cbe8f87"
      },
      "source": [
        "basedir"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/models_for_github'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwkFlJH-3BC2",
        "outputId": "b2522437-3841-4cef-d2ce-a8eac94715ea"
      },
      "source": [
        "onsets_db.files"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MusicDelta_Disco_Drum',\n",
              " 'MusicDelta_Britpop_Drum',\n",
              " 'MusicDelta_Rock_Drum',\n",
              " 'MusicDelta_BebopJazz_Drum',\n",
              " 'MusicDelta_Shadows_Drum',\n",
              " 'MusicDelta_Reggae_Drum',\n",
              " 'MusicDelta_CoolJazz_Drum',\n",
              " 'MusicDelta_Rockabilly_Drum',\n",
              " 'MusicDelta_FunkJazz_Drum',\n",
              " 'MusicDelta_FusionJazz_Drum',\n",
              " 'MusicDelta_80sRock_Drum']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYLdSKiK3Xs3"
      },
      "source": [
        "# we will select our validation set, notrandomly\n",
        "all_files = onsets_db.files\n",
        "validation_files = [\"MusicDelta_Britpop_Drum\", 'MusicDelta_Rock_Drum', 'MusicDelta_FunkJazz_Drum']\n",
        "train_files = list( set(all_files) - set(validation_files) )\n",
        "assert len(all_files) == (len(train_files) + len(validation_files)),\"Error\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxyCcVeZ4C1U",
        "outputId": "2b5b8c75-5495-444d-ef4b-7c354a67d11f"
      },
      "source": [
        "# now we retrieve the indexes\n",
        "validation_files_indexes = [onsets_db.files.index(validation_files[val_idx]) for val_idx in range(len(validation_files))]\n",
        "train_files_indexes = [onsets_db.files.index(train_files[train_idx]) for train_idx in range(len(train_files))]\n",
        "validation_files_indexes"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u6BW_pfrmbT",
        "outputId": "279286e6-5054-498b-ea75-b0779c886a3d"
      },
      "source": [
        "idx = 0\n",
        "print(f\"File name is {onsets_db.files[idx]}\")\n",
        "onset = onsets_db.x[idx]\n",
        "annotation = onsets_db.annotations[idx]\n",
        "print(\"Onset shape is\",onset.shape)\n",
        "quantize_onset = madmom.utils.quantize_events(annotation, fps=FPS, length = len(onset))\n",
        "print(\"Quantized resulting shape is:\",quantize_onset.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File name is MusicDelta_Disco_Drum\n",
            "Onset shape is (12478, 314)\n",
            "Quantized resulting shape is: (12478,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mExeQBSqsK54",
        "outputId": "b59ce7bf-5713-41fa-b2d6-2071015cd069"
      },
      "source": [
        "quantize_onset.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12478,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuh13kPGSrlm"
      },
      "source": [
        "# Prepare splits for minibatch training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LIJVBLYSo6g"
      },
      "source": [
        "train = DataSequence([onsets_db.x[i] for i in train_files_indexes],\n",
        "                     [onsets_db.annotations[i] for i in train_files_indexes],\n",
        "                      batch_size=1, max_seq_length=60 * FPS)\n",
        "                             \n",
        "val = DataSequence([onsets_db.x[i] for i in validation_files_indexes],\n",
        "                   [onsets_db.annotations[i] for i in validation_files_indexes],\n",
        "                    batch_size=1, max_seq_length=60 * FPS)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHSBQiKiSsyw",
        "outputId": "a3297e11-cba1-4131-aad3-dbb7df9b4da1"
      },
      "source": [
        "train.batch_size"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxhE1SEvpK1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e74b0a-ccd2-4cea-d931-37416ecdb632"
      },
      "source": [
        "onset_idx = 1\n",
        "x_example, y_example = train.x[onset_idx],train.y[onset_idx]\n",
        "print(f\"Example shape x is {x_example.shape}\")\n",
        "print(f\"Example shape y is {y_example.shape}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example shape x is (11099, 314)\n",
            "Example shape y is (11099,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I did it with n_epochs = 100 but 10 epochs is enough for showing the example"
      ],
      "metadata": {
        "id": "gvbYqisguSSe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIQR75KhTIx9"
      },
      "source": [
        "# few parameters\n",
        "nn_params = {\n",
        "    \"learning_rate\":0.01,\n",
        "    \"n_epochs\":10, # TODO set this to 100\n",
        "    \"momentum\":0.93\n",
        "}\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2gsgGoMTTdX",
        "outputId": "54a08bc2-fcdc-4605-bf0a-1c12b68aa7eb"
      },
      "source": [
        "load_preexisinng_model = False\n",
        "last_epoch_model_name = \"\" # enter last epoch  model name in case is needed\n",
        "#\n",
        "if load_preexisinng_model:\n",
        "  current_model = os.path.join(basedir, last_epoch_model_name)\n",
        "  print(f\"[INFO] Loading model from {current_model}\")\n",
        "  model = keras.models.load_model(current_model)\n",
        "else:\n",
        "  print(\"[INFO] Creating model from scratch\")\n",
        "  model = Sequential()\n",
        "  model.add(Masking(input_shape=(None, train[0][0].shape[-1]), mask_value=train.mask_value))\n",
        "  model.add(Bidirectional(SimpleRNN(units=25, return_sequences=True)))\n",
        "  model.add(Bidirectional(SimpleRNN(units=25, return_sequences=True)))\n",
        "  model.add(Bidirectional(SimpleRNN(units=25, return_sequences=True)))\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=nn_params[\"learning_rate\"],\n",
        "                                                  clipvalue=5,\n",
        "                                                  momentum=nn_params[\"momentum\"]),\n",
        "                metrics=['binary_accuracy'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Creating model from scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm-k2mSATqn2",
        "outputId": "7fdb1832-7c0f-48f7-ed6b-8dc9e803cd88"
      },
      "source": [
        "verbose=0\n",
        "print(f\"WE WILL BE WRITING CHECKPOINTS HERE:{basedir}\")\n",
        "mca = keras.callbacks.ModelCheckpoint(basedir + '/model_'+example_suffix+'_{epoch:02d}.h5',\n",
        "                                      monitor='loss',\n",
        "                                      save_best_only=False,\n",
        "                                      save_weights_only=False,\n",
        "                                      mode='auto',\n",
        "                                      save_freq=8)\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                   min_delta=1e-4,\n",
        "                                   patience=20, \n",
        "                                   verbose=verbose)\n",
        "tb = keras.callbacks.TensorBoard(log_dir=basedir + '/logs',\n",
        "                                 write_graph=True,\n",
        "                                 write_images=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WE WILL BE WRITING CHECKPOINTS HERE:/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/models_for_github\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZftKUUcryl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f107f0f5-4fc2-4e00-fd6d-3d504c7a55ea"
      },
      "source": [
        "# change this booll in case you wanna retrain the model\n",
        "train_model = True\n",
        "if train_model:\n",
        "  history = model.fit_generator(train,\n",
        "                                steps_per_epoch=len(train),\n",
        "                                epochs=nn_params[\"n_epochs\"],\n",
        "                                shuffle=True,\n",
        "                                validation_data=val,\n",
        "                                validation_steps=len(val),\n",
        "                                callbacks=[mca, es, tb])\n",
        "  model.save(basedir + f'/model_final_{example_suffix}.h5')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 330s 33s/step - loss: 0.3874 - binary_accuracy: 0.7638 - val_loss: 0.2281 - val_binary_accuracy: 0.9379\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 318s 44s/step - loss: 0.2012 - binary_accuracy: 0.9469 - val_loss: 0.2478 - val_binary_accuracy: 0.9379\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 304s 42s/step - loss: 0.1976 - binary_accuracy: 0.9469 - val_loss: 0.2216 - val_binary_accuracy: 0.9379\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 298s 34s/step - loss: 0.1843 - binary_accuracy: 0.9469 - val_loss: 0.2137 - val_binary_accuracy: 0.9379\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 307s 34s/step - loss: 0.1787 - binary_accuracy: 0.9469 - val_loss: 0.1956 - val_binary_accuracy: 0.9379\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 311s 44s/step - loss: 0.1655 - binary_accuracy: 0.9469 - val_loss: 0.1871 - val_binary_accuracy: 0.9379\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 308s 44s/step - loss: 0.1589 - binary_accuracy: 0.9483 - val_loss: 0.1773 - val_binary_accuracy: 0.9394\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 318s 37s/step - loss: 0.1513 - binary_accuracy: 0.9481 - val_loss: 0.1684 - val_binary_accuracy: 0.9409\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 306s 35s/step - loss: 0.1459 - binary_accuracy: 0.9493 - val_loss: 0.1621 - val_binary_accuracy: 0.9416\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 307s 36s/step - loss: 0.1396 - binary_accuracy: 0.9493 - val_loss: 0.1590 - val_binary_accuracy: 0.9421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxqXDFlt99vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b06a7f-6085-47f4-9bbc-11d72043da8f"
      },
      "source": [
        "os.listdir(basedir)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['onsets',\n",
              " 'logs',\n",
              " 'model_for_github_01.h5',\n",
              " 'model_for_github_02.h5',\n",
              " 'model_for_github_03.h5',\n",
              " 'model_for_github_04.h5',\n",
              " 'model_for_github_05.h5',\n",
              " 'model_for_github_06.h5',\n",
              " 'model_for_github_07.h5',\n",
              " 'model_for_github_08.h5',\n",
              " 'model_for_github_09.h5',\n",
              " 'model_for_github_10.h5',\n",
              " 'model_for_github.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlBPlxxP-wCL",
        "outputId": "802ae770-e959-47bc-b46c-ebe87c61f05c"
      },
      "source": [
        "last_epoch_model_name = f\"model_final_{example_suffix}.h5\"\n",
        "current_model_path = os.path.join(basedir, last_epoch_model_name)\n",
        "model = keras.models.load_model(current_model_path)\n",
        "model"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f6a286ccc10>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Predict on the heldout set and save them into a pickle (so we can handle them later on the evals_. notebook) "
      ],
      "metadata": {
        "id": "iX8eKSkzvpI_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHKqzWSASyzH",
        "outputId": "355e3fd0-7034-412e-8331-0debd09d5d03"
      },
      "source": [
        "ANNOTATIONS_DIR_TEST = os.path.join(MUSIC_DIR,\"annotations\",\"class\",\"test\" )#/class/train\"\n",
        "annotation_files_all_test = glob.glob(ANNOTATIONS_DIR_TEST +\"/*.txt\")\n",
        "audio_files_all_test = [search_correspondingpath_given_annotation(annotation, ONSET_PATH)  for annotation in annotation_files_all_test ]\n",
        "# tomo el nombre base con el suffix\n",
        "files_test = [os.path.basename(file) for file in audio_files_all_test]\n",
        "#le saco el suffix\n",
        "files_test = [file.split(\".\")[0] for file in files_test ]\n",
        "onsets_db_test = Dataset(path = ONSET_PATH, files = files_test, annotation_files = annotation_files_all_test, audio_files= audio_files_all_test)\n",
        "\n",
        "\n",
        "path2dump_preprocess_test = os.path.join(MUSIC_DIR,f\"onset_db_test_{example_suffix}.pkl\")\n",
        "print(\"[INFO] Preprocessing files\")\n",
        "if not os.path.exists(path2dump_preprocess_test):\n",
        "  #load the annotations\n",
        "  print(\"[INFO] Loading the annotations\")\n",
        "  onsets_db_test.load_annoatations()\n",
        "  print(\"[INFO] Pre processing the files\")\n",
        "  onsets_db_test.pre_process(pp)\n",
        "  pickle.dump(onsets_db_test, open(path2dump_preprocess_test, 'wb'), protocol=2)\n",
        "  print(f\"Pickle dumped to: {path2dump_preprocess_test} \")\n",
        "else:\n",
        "  print(f\"Loading previously dumped pickle from: {path2dump_preprocess_test}\")\n",
        "  onsets_db_test = pickle.load(open(path2dump_preprocess_test,'rb'))\n",
        "print(\"[INFO] Preprocessing finished\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Preprocessing files\n",
            "[INFO] Loading the annotations\n",
            "[INFO] Pre processing the files\n",
            "Pickle dumped to: /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/onset_db_test_for_github.pkl \n",
            "[INFO] Preprocessing finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wY3kKikYwO2",
        "outputId": "8168cfd9-24b4-4555-8b58-71a289c9c4f1"
      },
      "source": [
        "onsets_db_test.audio_files"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_Hendrix_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_SwingJazz_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_FreeJazz_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_Beatles_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_Country1_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_SpeedMetal_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_Punk_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_ModalJazz_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_Gospel_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_LatinJazz_Drum.wav',\n",
              " '/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/audio/drum_only/test/MusicDelta_Grunge_Drum.wav']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lXpUFokVjv8",
        "outputId": "4ad6826e-d393-4529-af4b-d36be2634072"
      },
      "source": [
        "# peak picking function\n",
        "#     fps : float, optional\n",
        "        #Frames per second used for conversion of timings.\n",
        "rnn_peak_picking = madmom.features.onsets.OnsetPeakPickingProcessor(\n",
        "        threshold=0.35, pre_max=0.01, post_max=0.01, smooth=0.07, combine=0.03, fps = FPS)\n",
        "\n",
        "#predicted_song_idx = 0\n",
        "n_songs2predict = len(onsets_db_test.audio_files)\n",
        "predictions_dfs_list = list()\n",
        "for predicted_song_idx in range(n_songs2predict):\n",
        "  print(f\"[INFO] Starting prediction for song_idx: {predicted_song_idx}\")\n",
        "  audio_path = onsets_db_test.audio_files[predicted_song_idx]\n",
        "  # load song j \n",
        "  reshaped_onset = onsets_db_test.x[predicted_song_idx]\n",
        "  # we will reshape with this; cahnge  dimensions from (K,M) to (1,K,M)\n",
        "  reshaped_onset = reshaped_onset[np.newaxis,...]\n",
        "  pred = model.predict(reshaped_onset)\n",
        "  # change dimentions from (1,K,1) to (K,)\n",
        "  pred = pred.squeeze()\n",
        "\n",
        "  # now pass ; so you get onset_time\n",
        "  final_onsets_song = rnn_peak_picking(pred)\n",
        "  df_pred = pd.DataFrame(final_onsets_song, columns=[\"onset_time\"])\n",
        "  df_pred[\"audio_path\"] = audio_path\n",
        "  df_pred = df_pred[[\"onset_time\",\"audio_path\"]]\n",
        "  predictions_dfs_list.append(df_pred)\n",
        "df_predictions_rnn = pd.concat(predictions_dfs_list, axis = 0 )\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Starting prediction for song_idx: 0\n",
            "[INFO] Starting prediction for song_idx: 1\n",
            "[INFO] Starting prediction for song_idx: 2\n",
            "[INFO] Starting prediction for song_idx: 3\n",
            "[INFO] Starting prediction for song_idx: 4\n",
            "[INFO] Starting prediction for song_idx: 5\n",
            "[INFO] Starting prediction for song_idx: 6\n",
            "[INFO] Starting prediction for song_idx: 7\n",
            "[INFO] Starting prediction for song_idx: 8\n",
            "[INFO] Starting prediction for song_idx: 9\n",
            "[INFO] Starting prediction for song_idx: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmSdr4S6XXeY",
        "outputId": "1185f4c8-25eb-47a7-b32a-d584eb64e957"
      },
      "source": [
        "predictions_onset_dataframe_path = os.path.join(basedir,f\"model_predictions_rnn_fulltrained_{example_suffix}.pkl\")\n",
        "if not os.path.exists(predictions_onset_dataframe_path):\n",
        "  df_predictions_rnn.to_pickle(predictions_onset_dataframe_path)\n",
        "  print(f\"Model predictions saved to {predictions_onset_dataframe_path}\")\n",
        "else:\n",
        "  raise ValueError(\"You cannot overwrite the file; please use os.remove(filepath) first\")\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predictions saved to /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/models_for_github/model_predictions_rnn_fulltrained_for_github.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We will load the saved predictions later for evaluating the onset detections combined with the recognition model"
      ],
      "metadata": {
        "id": "yPA5YytR_Ohw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zNkNmMqVV4SX",
        "outputId": "c0d5cba1-fdc2-4c99-f94f-db54ad531bf5"
      },
      "source": [
        "model_predictions_path_hardcoded = f'/content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/models_for_github/model_predictions_rnn_fulltrained_{example_suffix}.pkl'\n",
        "df_predictions_rnn = pd.read_pickle(model_predictions_path_hardcoded)\n",
        "df_predictions_rnn"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     onset_time                                         audio_path\n",
              "0          0.02  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "1          0.29  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "2          0.57  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "3          1.00  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "4          1.38  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "..          ...                                                ...\n",
              "112       38.99  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "113       39.26  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "114       39.53  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "115       39.81  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "116       40.08  /content/drive/My Drive/Maestria DM y KDD/Espe...\n",
              "\n",
              "[1603 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b54891ef-d1d4-472a-9e27-4b3dfa87b2a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>onset_time</th>\n",
              "      <th>audio_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.02</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.29</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.57</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.00</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.38</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>38.99</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>39.26</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>39.53</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>39.81</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>40.08</td>\n",
              "      <td>/content/drive/My Drive/Maestria DM y KDD/Espe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1603 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b54891ef-d1d4-472a-9e27-4b3dfa87b2a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b54891ef-d1d4-472a-9e27-4b3dfa87b2a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b54891ef-d1d4-472a-9e27-4b3dfa87b2a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}