{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaYla0WTiIOn",
        "outputId": "6ffac6ad-e523-4800-eb4f-3df4506b736d"
      },
      "source": [
        "script_idea = \"\"\"\n",
        "Script intended to train 1 NN for each drumtype, this is the SOFTMAX version.\n",
        "Before training the model, you have to preprocess the songs and the annotations \n",
        "After processing, everything is going to EXP_PIPE_DATA (path, see bellow)\n",
        "\"\"\"\n",
        "print(script_idea)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Script intended to train 1 NN for each drumtype, this is the SOFTMAX version.\n",
            "Before training the model, you have to preprocess the songs and the annotations \n",
            "After processing, everything is going to EXP_PIPE_DATA (path, see bellow)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS5TRims5WaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70cff56-360e-4fdb-f5d2-94fcbcb84bb7"
      },
      "source": [
        "# Which instrument you want to run the pipeline for; ie if target_label = \"HH\" -> create model for hihat. \n",
        "target_label = \"HH\"\n",
        "\n",
        "# preprocess modules\n",
        "import librosa\n",
        "from librosa import display\n",
        "import os,sys,re,pandas as pd,numpy as np\n",
        "from scipy.io import wavfile\n",
        "import math\n",
        "from sympy import Interval\n",
        "# viz\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, recall_score, precision_score\n",
        "# torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "# other\n",
        "import random\n",
        "import logging\n",
        "import glob\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "ROOT_DIR = \"/content/drive\"\n",
        "#  Just use this if you are using google as a bucket\n",
        "drive.mount(ROOT_DIR, force_remount=True)\n",
        "# Don't forget to type My Drive before the whole path (in case you are using gdrive)\n",
        "# In case you're not using gdrive; MUSIC_DIR should be your rootdir\n",
        "MUSIC_DIR = os.path.join(ROOT_DIR,'My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums')\n",
        "AUDIO_DIR = os.path.join(MUSIC_DIR,'audio','drum_only')\n",
        "ANNOTATIONS_DIR = os.path.join(MUSIC_DIR,'annotations','class')\n",
        "# where your preprocessed data is for train & test (for the preprocesing script see )\n",
        "EXP_PIPE_DATA = os.path.join(MUSIC_DIR,\"pipe005_multiplemodelsdata_corrected_over60\")\n",
        "EXP_PIPE_DATA_TRAIN = os.path.join(EXP_PIPE_DATA,\"train\")\n",
        "EXP_PIPE_DATA_TEST = os.path.join(EXP_PIPE_DATA,\"test\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPrVlqsTscub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06964106-e509-4938-bda7-0194429846ab"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/tesis_esp\n",
        "import trainmodel_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/tesis_esp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reproductibility\n",
        "myseed = 1995\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "D5o-r93QsCgl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayru0Sh8BQlg"
      },
      "source": [
        "#get filepaths\n",
        "file_paths_txt_train = glob.glob(EXP_PIPE_DATA_TRAIN+\"/*.txt\")\n",
        "file_paths_npy_train = glob.glob(EXP_PIPE_DATA_TRAIN+\"/*.npy\")\n",
        "# we should this one in the evaluation script, not in this one\n",
        "file_paths_txt_test = glob.glob(EXP_PIPE_DATA_TEST+\"/*.txt\")\n",
        "file_paths_npy_test = glob.glob(EXP_PIPE_DATA_TEST+\"/*.npy\")\n",
        "## ------------params ------------\n",
        "train_ratio = 0.8\n",
        "validation_ratio = 0.2 # you should use then after\n",
        "# test_ratio = 0.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logfile_path = os.path.join(EXP_PIPE_DATA,f'Softmax_CE_nn_model_{target_label}_logfile.log')\n",
        "logging.basicConfig(filename = logfile_path, format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%m/%d/%Y %I:%M:%S %p')\n",
        "file_paths_txt_targeted,file_paths_npy_targeted = trainmodel_utils.filter_path_for_target_label(file_paths_txt_train,file_paths_npy_train,target_label)\n",
        "\n",
        "# load all data in memory\n",
        "labels_list,data_npy_list = trainmodel_utils.load_labels_and_data_from_npy(file_paths_npy_all = file_paths_npy_targeted)\n",
        "data = trainmodel_utils.merge_numpy_data(data_npy_list) # X\n",
        "labels = trainmodel_utils.merge_labels_data(labels_list) # y\n",
        "assert data.shape[0] == len(labels)\n",
        "print(f\" Dataset is of {data.shape[0]} onsets, \\n with a 33x9 (64-> window size, strides of 16 to a padded signal of len 128\")\n",
        "# x_train, x_val, x_test,y_train,y_val,y_test = trainmodel_utils.trainvaltest_split(data,labels,train_ratio,validation_ratio,test_ratio, myseed)\n",
        "# remember: if none, then it will be stratified by y.\n",
        "x_train, x_val, y_train, y_val = train_test_split(data,labels,test_size=validation_ratio,random_state=myseed, stratify = None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u84yTX4Qr4TY",
        "outputId": "0b3adb2c-5ff6-4c07-b9e4-6045dfdcd929"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Disco_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Disco_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Britpop_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Britpop_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Rock_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Rock_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_BebopJazz_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_BebopJazz_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Shadows_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Shadows_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Reggae_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Reggae_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_CoolJazz_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_CoolJazz_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Rockabilly_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_Rockabilly_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_FunkJazz_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_FunkJazz_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_FusionJazz_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_FusionJazz_class__HH.npy\n",
            "User must verify if the following files correspoond eaco other :\n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_80sRock_class__HH.txt \n",
            " /content/drive/My Drive/Maestria DM y KDD/Especializacion tesis/MDBDrums/MDB Drums/pipe005_multiplemodelsdata_corrected_over60/train/MusicDelta_80sRock_class__HH.npy\n",
            " Dataset is of 3247 onsets, \n",
            " with a 33x9 (64-> window size, strides of 16 to a padded signal of len 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lYdBVyHfiq7",
        "outputId": "bbb4715e-3468-4eb2-912a-e4b5338a5235"
      },
      "source": [
        "print(\"Data shape is:\",data.shape)\n",
        "print(\"Unique labels are:\",set(labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape is: (3247, 513, 17)\n",
            "Unique labels are: {'HH', 'OTHER'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUlvIqGZl9EL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608c3cb0-233f-444d-ec09-0e28f8ec4f50"
      },
      "source": [
        "# come from this unique_labels = list(set(labels)) \n",
        "unique_labels = [target_label,'OTHER']\n",
        "unique_labels_idx = [idx for idx in range(len(unique_labels))]\n",
        "unique_labels"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['HH', 'OTHER']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeld_yZTzF0"
      },
      "source": [
        "def map_labels2idx(label_list2map, unique_labels):\n",
        "  \"map labels from unique_labels to its respective index\"\n",
        "  mapped_labels = [unique_labels.index(label_idx) for label_idx in label_list2map]\n",
        "  return mapped_labels\n",
        "  \n",
        "def map_idx2labels(mapped_labels,unique_labels=unique_labels):\n",
        "  labels = list()\n",
        "  for idx in range(len(mapped_labels)):\n",
        "    mapped_lab = mapped_labels[idx]\n",
        "    label_name = unique_labels[mapped_lab]\n",
        "    labels.append(label_name)\n",
        "  return labels"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RPuOaWmmVJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88d94b7-e01e-4bb3-82f1-dbe30bf1175f"
      },
      "source": [
        "labels_indexes = map_labels2idx(labels, unique_labels)\n",
        "nclasses = len(unique_labels_idx)\n",
        "print(labels[:5],labels_indexes[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HH', 'HH', 'HH', 'HH', 'OTHER'] [0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M1OHFNq4goG"
      },
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(myseed)\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  Data loader for mini batch processing in pytorch\n",
        "  Based on https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel \n",
        "  \"\"\"\n",
        "  def __init__(self, data_tensor, labels):\n",
        "        'Initialization'\n",
        "        self.labels = labels\n",
        "        self.data_tensor = data_tensor\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        X = self.data_tensor[index] #torch.tensor of 65x17 \n",
        "        y = self.labels[index]\n",
        "        return X, y"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09TodMZKESkJ"
      },
      "source": [
        "logging.info(f\"Using the following random state for trainvaltest split: {myseed}\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mKhLesaodf2",
        "outputId": "24a0339c-21ea-4402-e49c-07012a11bf3e"
      },
      "source": [
        "y_train2idx = map_labels2idx(y_train, unique_labels)\n",
        "data_tensor_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "N,H,W = data_tensor_train.shape\n",
        "data_tensor_train = data_tensor_train.reshape(N,1,H,W)\n",
        "print(f\"trai ndataset shape: {data_tensor_train.shape}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trai ndataset shape: torch.Size([2597, 1, 513, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTILAAxXG8LX",
        "outputId": "aea6cc31-24ec-4f03-b2af-18029264e992"
      },
      "source": [
        "# validation\n",
        "y_val2idx = map_labels2idx(y_val, unique_labels)\n",
        "data_tensor_val = torch.tensor(x_val, dtype=torch.float32)\n",
        "N,H,W = data_tensor_val.shape\n",
        "data_tensor_val = data_tensor_val.reshape(N,1,H,W)\n",
        "print(f\"val ndataset shape: {data_tensor_val.shape}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val ndataset shape: torch.Size([650, 1, 513, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9sGQw2YuppQ",
        "outputId": "ec99504a-c204-44ee-9ced-ea220025f29b"
      },
      "source": [
        "method = \"meanstd_normalize\"\n",
        "\n",
        "if method == \"meanstd_normalize\":\n",
        "  train_mean, train_std = data_tensor_train.mean(), data_tensor_train.std()\n",
        "  normalize_train_data = {\"mean\":train_mean, \"std\":train_std}\n",
        "  meanstd_normalize = torchvision.transforms.Normalize(**normalize_train_data, inplace=False) \n",
        "  print(f\"applying {method}\")\n",
        "  data_tensor_train_norm = meanstd_normalize(data_tensor_train)\n",
        "  data_tensor_val_norm = meanstd_normalize(data_tensor_val)\n",
        "elif method == \"minmax_normalize\":\n",
        "  train_max,trainmin = data_tensor_train.max(),data_tensor_train.min()\n",
        "  train_maxmin_diff  =train_max-trainmin\n",
        "  minmax_normalize = torchvision.transforms.Normalize(mean = trainmin, std = train_maxmin_diff, inplace=False) \n",
        "  print(f\"applying {method}\")\n",
        "  data_tensor_train_norm = minmax_normalize(data_tensor_train)\n",
        "  data_tensor_val_norm = minmax_normalize(data_tensor_val)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "applying meanstd_normalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vWTvmv3bpz_"
      },
      "source": [
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': 128,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 2}\n",
        "n_epochs = 30\n",
        "\n",
        "# Generators\n",
        "training_set = Dataset(data_tensor_train_norm, y_train2idx)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set  = Dataset(data_tensor_val_norm, y_val2idx)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1qZ5iiZcWGC",
        "outputId": "c8b946f3-5042-41e2-a189-51c2f3e58080"
      },
      "source": [
        "nexamples2show = 5\n",
        "testiter = iter(training_set) #start the iterator\n",
        "for i in range(nexamples2show):\n",
        "  first_x,first_y = next(testiter)\n",
        "  print(f\"Observation nubmer {i} has labelidx:{first_y} and shape {first_x.shape}\")\n",
        " "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation nubmer 0 has labelidx:1 and shape torch.Size([1, 513, 17])\n",
            "Observation nubmer 1 has labelidx:1 and shape torch.Size([1, 513, 17])\n",
            "Observation nubmer 2 has labelidx:0 and shape torch.Size([1, 513, 17])\n",
            "Observation nubmer 3 has labelidx:1 and shape torch.Size([1, 513, 17])\n",
            "Observation nubmer 4 has labelidx:0 and shape torch.Size([1, 513, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4z8GEX95h1p"
      },
      "source": [
        "#https://towardsdatascience.com/beginners-guide-to-loading-image-data-with-pytorch-289c60b7afec\n",
        "\n",
        "def evaluate_data_pytorch(data_generator:torch.utils.data.DataLoader,pytorch_net,sklearnmetric:str ='classification_report') ->str:\n",
        "  \"\"\"\n",
        "  Function for evaluating validation set using torch dataloader. \n",
        "  taken/based on https://towardsdatascience.com/beginners-guide-to-loading-image-data-with-pytorch-289c60b7afec\n",
        "  Params:\n",
        "    data_generator -> must be pytorch generator \n",
        "    pytorch_net: -> pytorch neural network\n",
        "    sklearnmetric: sklearn metric that requires y_true and y_pred ; could be classification_report or f1_score or other\n",
        "  \"\"\"\n",
        "  #data_generator = validation_generator\n",
        "  truelabels_val,predictedlabels_val = list(),list()\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for i, data in enumerate(data_generator, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          if not cuda:\n",
        "            inputs, labels = data\n",
        "          if cuda:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "          # forward + backward + optimize\n",
        "          #print(inputs.shape)\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          #print(predicted)\n",
        "          #total += labels.size(0)\n",
        "          truelabels_val.extend(labels.tolist())\n",
        "          predictedlabels_val.extend(predicted.tolist())\n",
        "          #correct += (predicted == labels).sum().item()\n",
        "  df_val = pd.DataFrame({\"truelabel\":truelabels_val,\"predicted\":predictedlabels_val})\n",
        "  df_val[\"lab_truelabel\"] = map_idx2labels(df_val[\"truelabel\"].tolist())\n",
        "  df_val[\"lab_predicted\"] = map_idx2labels(df_val[\"predicted\"].tolist())\n",
        "  pd.crosstab(df_val[\"lab_truelabel\"],df_val[\"lab_predicted\"])\n",
        "\n",
        "  if sklearnmetric == \"classification_report\":\n",
        "    cr = classification_report(y_true=df_val[\"lab_truelabel\"].tolist(),y_pred=df_val[\"lab_predicted\"].tolist(), output_dict = True)\n",
        "  elif sklearnmetric == \"f1_score_weighted\":\n",
        "    cr = f1_score(y_true=df_val[\"lab_truelabel\"].tolist(),y_pred=df_val[\"lab_predicted\"].tolist(),average = 'weighted')\n",
        "  else:\n",
        "    raise ValueError(\"Please  sklearn metric mustbe classification_report or f1_score with avergage weighted\")      \n",
        "  return cr"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define network architecture (cnn)"
      ],
      "metadata": {
        "id": "uc9V88Pgvmbg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6JRSBtT5jff"
      },
      "source": [
        "cuda = False\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,nchannels,nclasses, unique_labels, meanstd_normalize):\n",
        "        \"\"\"\n",
        "        Params:\n",
        "          unique_labels: list of labels to be mapped; example: ['OTHER','KD'] \n",
        "          meanstd_normalize:  output from torchvision.transforms.Normalize; for zscaling \n",
        "              o             the data\n",
        "          prediction_threshold: float in (0,1) interval; if proba>threshold then\n",
        "                        predicted class will be TARGET else other. \n",
        "          nclasses of the net; 2 in this case since we are applying binary classif\n",
        "        \"\"\"\n",
        "        # start\n",
        "        super().__init__()\n",
        "        # this is the normalizer to used in the predictor then\n",
        "        self.meanstd_normalizer = torchvision.transforms.Normalize(**meanstd_normalize, inplace=False) \n",
        "        # remove it if you want to this is jsut for cleaner predictions (use labels instead of etc)\n",
        "        self.unique_labels = unique_labels\n",
        "        # other attributes\n",
        "        self.nchannels = nchannels\n",
        "        self.nclasses = nclasses\n",
        "        self.conv1 = nn.Conv2d(self.nchannels, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(2000, 120)\n",
        "        self.dropout1 = nn.Dropout(p=0.5, inplace=False)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        #self.dropout2 = nn.Dropout(p=0.3, inplace=False)\n",
        "        self.fc3 = nn.Linear(84, self.nclasses)\n",
        "    def forward(self, x):\n",
        "        \"Prints are commented for debugging purposes\"\n",
        "        # conv1 \n",
        "        x = self.conv1(x)\n",
        "        #print(\"Conv1:\",x.shape)\n",
        "        x =F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        #print(\"Pool1:\",x.shape)\n",
        "        x = self.conv2(x)\n",
        "        #print(\"Conv2:\",x.shape)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        #print(\"Pool2:\",x.shape)\n",
        "        # flatten  all dims except the batch; \n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        #print(\"Flattened, except batch:\",x.shape)\n",
        "        x = self.fc1(x)\n",
        "        x=F.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        # pass over relu\n",
        "        x = F.relu(x)\n",
        "        #\n",
        "        #x = self.dropout2(x)\n",
        "        # pass over fc3 omg\n",
        "        x = self.fc3(x)\n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
        "        return x\n",
        "    def map_idx2labels(self,mapped_labels,unique_labels):\n",
        "      labels = list()\n",
        "      for idx in range(len(mapped_labels)):\n",
        "        mapped_lab = mapped_labels[idx]\n",
        "        label_name = unique_labels[mapped_lab]\n",
        "        labels.append(label_name)\n",
        "      return labels\n",
        "\n",
        "    def predict(self,x_batch):\n",
        "      \"\"\"\n",
        "      Final prediction function\n",
        "      params:\n",
        "        x_batch -> np.array model dimensions data_lenx513x17 data\n",
        "      return: mapped prediction (either target label or other)\n",
        "      \"\"\"\n",
        "      #x_batch = x_test[:10].copy()\n",
        "      #N = len(x_batch)\n",
        "      data_tensor = torch.tensor(x_batch, dtype=torch.float32)\n",
        "      N,H,W = data_tensor.shape\n",
        "      print(N,H,W)\n",
        "      data_tensor = data_tensor.reshape(N,1,H,W)\n",
        "      # noramalize data\n",
        "      data_tensor = self.meanstd_normalizer(data_tensor)\n",
        "      #forward pass\n",
        "      predictions = self.forward(data_tensor)\n",
        "      # calculate the .max(1) for each batch and convert them to list\n",
        "      predictions = predictions.argmax(1).tolist()\n",
        "      predictions2labels = self.map_idx2labels(predictions,self.unique_labels)\n",
        "      return predictions2labels\n",
        "\n",
        "#todo\n",
        "net = Net(nchannels=1,nclasses=nclasses, unique_labels=unique_labels, meanstd_normalize=normalize_train_data)\n",
        "if cuda:\n",
        "  net.to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start training the net without early stopping (n_epochs = 10 just for the example)"
      ],
      "metadata": {
        "id": "CvjxdZb9wL1c"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUwU4kGkru_R",
        "outputId": "6f2f5d49-7953-4375-821e-b1aac31d2adf"
      },
      "source": [
        "f1_train_list,f1_val_list,epoch_number = list(),list(),list()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0)\n",
        "metric2monitor = \"f1-score\"\n",
        "#optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(training_generator, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        if not cuda:\n",
        "          inputs, labels = data\n",
        "        if cuda:\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "        #   print(outputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    cr_train = evaluate_data_pytorch(training_generator,pytorch_net = net,sklearnmetric='classification_report')[target_label][metric2monitor]\n",
        "    cr_val = evaluate_data_pytorch(validation_generator,pytorch_net = net,sklearnmetric='classification_report')[target_label][metric2monitor]\n",
        "    f1_train_list.append(cr_train)\n",
        "    f1_val_list.append(cr_val)\n",
        "    epoch_number.append(epoch)\n",
        "    print(f\" [INFO] Epoch number: {epoch}\")\n",
        "print('[INFO] Finished Training')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [INFO] Epoch number: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [INFO] Epoch number: 1\n",
            " [INFO] Epoch number: 2\n",
            " [INFO] Epoch number: 3\n",
            " [INFO] Epoch number: 4\n",
            " [INFO] Epoch number: 5\n",
            " [INFO] Epoch number: 6\n",
            " [INFO] Epoch number: 7\n",
            " [INFO] Epoch number: 8\n",
            " [INFO] Epoch number: 9\n",
            " [INFO] Epoch number: 10\n",
            " [INFO] Epoch number: 11\n",
            " [INFO] Epoch number: 12\n",
            " [INFO] Epoch number: 13\n",
            " [INFO] Epoch number: 14\n",
            " [INFO] Epoch number: 15\n",
            " [INFO] Epoch number: 16\n",
            " [INFO] Epoch number: 17\n",
            " [INFO] Epoch number: 18\n",
            " [INFO] Epoch number: 19\n",
            " [INFO] Epoch number: 20\n",
            " [INFO] Epoch number: 21\n",
            " [INFO] Epoch number: 22\n",
            " [INFO] Epoch number: 23\n",
            " [INFO] Epoch number: 24\n",
            " [INFO] Epoch number: 25\n",
            " [INFO] Epoch number: 26\n",
            " [INFO] Epoch number: 27\n",
            " [INFO] Epoch number: 28\n",
            " [INFO] Epoch number: 29\n",
            "[INFO] Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "w2keIsfyk-nb",
        "outputId": "8ce32639-028f-4adc-bac1-5ddbf7ea7309"
      },
      "source": [
        "df_train = pd.DataFrame({\"f1_score\":f1_train_list,\"epoch\":epoch_number,\"dataset_type\":\"training\"})\n",
        "df_val = pd.DataFrame({\"f1_score\":f1_val_list,\"epoch\":epoch_number,\"dataset_type\":\"validation\"})\n",
        "df_trainval = pd.concat([df_train,df_val],axis=0)\n",
        "fig = px.line(df_trainval, x=\"epoch\", y=\"f1_score\", color='dataset_type')\n",
        "fig.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"172154df-0af9-402d-bcb6-fef126bd4de2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"172154df-0af9-402d-bcb6-fef126bd4de2\")) {                    Plotly.newPlot(                        \"172154df-0af9-402d-bcb6-fef126bd4de2\",                        [{\"hovertemplate\":\"dataset_type=training<br>epoch=%{x}<br>f1_score=%{y}<extra></extra>\",\"legendgroup\":\"training\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"training\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"xaxis\":\"x\",\"y\":[0.0,0.6174384647476012,0.67425320056899,0.6611632270168856,0.6719595813785637,0.6919155134741443,0.7361018084393839,0.7576083064804869,0.8270793036750483,0.8777686628383922,0.8885324779470731,0.8624502432551968,0.9012244897959185,0.8860544217687074,0.9354047424366312,0.9219677692960137,0.9242364141213804,0.9336691855583543,0.9463647199046483,0.9395348837209302,0.947324414715719,0.9558823529411764,0.9551255660765748,0.959504132231405,0.9466666666666667,0.926829268292683,0.9627811860940695,0.9623188405797102,0.966612377850163,0.9483050847457627],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"dataset_type=validation<br>epoch=%{x}<br>f1_score=%{y}<extra></extra>\",\"legendgroup\":\"validation\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"validation\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"xaxis\":\"x\",\"y\":[0.0,0.5979729729729729,0.6799999999999999,0.6453576864535768,0.685878962536023,0.6784140969162995,0.7352941176470589,0.7760342368045648,0.8091603053435115,0.869983948635634,0.8680445151033387,0.8601398601398601,0.8942307692307693,0.8911222780569514,0.9406099518459069,0.9169435215946845,0.9216300940438872,0.9263502454991818,0.9278996865203761,0.9279731993299832,0.9271523178807947,0.9549839228295821,0.9497568881685575,0.9494290375203914,0.9306930693069307,0.9286898839137645,0.9423076923076924,0.9546925566343042,0.9519230769230769,0.9401993355481728],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"f1_score\"}},\"legend\":{\"title\":{\"text\":\"dataset_type\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('172154df-0af9-402d-bcb6-fef126bd4de2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_trainval = df_trainval.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "a4C3q_Bmz6ed"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "fJvP36TYnGB8",
        "outputId": "6a4971ac-1796-4c3e-cb7d-bdc0fc0746a0"
      },
      "source": [
        "figpath2save = os.path.join(EXP_PIPE_DATA,f\"refactored_example_for_github_nn_fig_model_{target_label}.jpeg\")\n",
        "sns_plot = sns.lineplot(x = df_trainval[\"epoch\"], y = df_trainval[\"f1_score\"] , hue = df_trainval[\"dataset_type\"])\n",
        "fig = sns_plot.get_figure()\n",
        "fig.savefig(figpath2save)\n",
        "fig.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb5BzMAvqaT5"
      },
      "source": [
        "modelpath2save = os.path.join(EXP_PIPE_DATA,f\"refactored_example_for_github_nn_model_{target_label}.pth\")\n",
        "torch.save(net,modelpath2save)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbVqqn_e0qO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c291e2-3acb-44c6-b0ef-a6095e6ac7b4"
      },
      "source": [
        "mm = torch.load(modelpath2save)\n",
        "mm"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (meanstd_normalizer): Normalize(mean=0.14862293004989624, std=1.0505046844482422)\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=2000, out_features=120, bias=True)\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EBdGURYV0EOK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}